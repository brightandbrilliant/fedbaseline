import os
import torch
from torch_geometric.data import Data
from collections import Counter
import numpy as np

# --- é…ç½® ---
# å‡è®¾æ‚¨çš„å®¢æˆ·ç«¯æ•°æ®å­å›¾æ–‡ä»¶ä½äºè¿™ä¸ªè·¯å¾„ä¸‹
DATA_DIR = "../parsed_dataset/cs"
PYG_DATA_FILES = sorted([os.path.join(DATA_DIR, f) for f in os.listdir(DATA_DIR) if f.endswith(".pt")])


def get_label_distribution(y: torch.Tensor, mask: torch.Tensor = None) -> Counter:
    """è·å–æŒ‡å®š Mask ä¸‹çš„æ ‡ç­¾åˆ†å¸ƒã€‚"""
    if mask is not None:
        y_masked = y[mask]
    else:
        y_masked = y

    # è¿‡æ»¤æ‰æ— æ•ˆæ ‡ç­¾ï¼ˆå¦‚ -1ï¼‰
    valid_labels = y_masked[y_masked >= 0].cpu().tolist()

    return Counter(valid_labels)


def analyze_client_data(file_path: str, client_id: int):
    """åŠ è½½å•ä¸ªå®¢æˆ·ç«¯æ•°æ®å¹¶æ‰“å°è¯¦ç»†ç»Ÿè®¡ä¿¡æ¯ã€‚"""
    print(f"\n--- ğŸ“Š å®¢æˆ·ç«¯ {client_id} ç»Ÿè®¡ä¿¡æ¯ ({os.path.basename(file_path)}) ---")

    try:
        data: Data = torch.load(file_path)
    except Exception as e:
        print(f"âŒ é”™è¯¯: æ— æ³•åŠ è½½æ–‡ä»¶ {file_path}. é”™è¯¯: {e}")
        return

    # 1. åŸºç¡€ä¿¡æ¯
    print(f"  - èŠ‚ç‚¹æ€»æ•° (N): {data.num_nodes}")
    print(f"  - è¾¹æ€»æ•° (E): {data.num_edges}")

    # 2. ç‰¹å¾å’Œæ ‡ç­¾ä¿¡æ¯
    if data.x is not None:
        print(f"  - èŠ‚ç‚¹ç‰¹å¾ç»´åº¦ (D_x): {data.x.shape[1]}")
    if data.y is not None:
        # è®¡ç®—æ‰€æœ‰èŠ‚ç‚¹çš„æœ‰æ•ˆæ ‡ç­¾æ•° (>= 0)
        num_valid_labels = (data.y >= 0).sum().item()
        print(f"  - èŠ‚ç‚¹æ ‡ç­¾æ€»æ•°: {data.y.numel()}")
        print(f"  - æœ‰æ•ˆæ ‡ç­¾èŠ‚ç‚¹æ•°: {num_valid_labels}")

        # è·å–æ‰€æœ‰æœ‰æ•ˆæ ‡ç­¾çš„åˆ†å¸ƒ
        full_distribution = get_label_distribution(data.y)
        total_valid_nodes = sum(full_distribution.values())
        print(f"  - æ ‡ç­¾åˆ†å¸ƒ (æ‰€æœ‰æœ‰æ•ˆèŠ‚ç‚¹): {total_valid_nodes} ä¸ªèŠ‚ç‚¹")
        for label, count in sorted(full_distribution.items()):
            print(f"    - ç±»åˆ« {label}: {count} ({count / total_valid_nodes:.2%})")

    # 3. è®­ç»ƒ/éªŒè¯/æµ‹è¯•åˆ’åˆ†ä¿¡æ¯
    has_masks = hasattr(data, 'train_mask') and data.train_mask is not None

    if has_masks:
        train_size = data.train_mask.sum().item()
        val_size = data.val_mask.sum().item()
        test_size = data.test_mask.sum().item()

        total_masked = train_size + val_size + test_size

        print(f"\n  --- åˆ’åˆ†ç»Ÿè®¡ (åŸºäº Mask) ---")
        print(f"  - è®­ç»ƒé›†èŠ‚ç‚¹æ•°: {train_size}")
        print(f"  - éªŒè¯é›†èŠ‚ç‚¹æ•°: {val_size}")
        print(f"  - æµ‹è¯•é›†èŠ‚ç‚¹æ•°: {test_size}")
        print(f"  - åˆ’åˆ†æ€»èŠ‚ç‚¹æ•°: {total_masked}")

        # 4. è®­ç»ƒé›†æ ‡ç­¾åˆ†å¸ƒ (Non-IID åˆ†ææ ¸å¿ƒ)
        if data.y is not None and train_size > 0:
            train_distribution = get_label_distribution(data.y, data.train_mask)
            total_train_valid = sum(train_distribution.values())

            print(f"\n  --- è®­ç»ƒé›†æ ‡ç­¾åˆ†å¸ƒ (N_{{train}} = {total_train_valid}) ---")
            for label, count in sorted(train_distribution.items()):
                print(f"    - ç±»åˆ« {label}: {count} ({count / total_train_valid:.2%})")

    else:
        print("\n  --- åˆ’åˆ†ç»Ÿè®¡ ---")
        print("  âš ï¸ è­¦å‘Š: å®¢æˆ·ç«¯æ•°æ®ä¸­æœªæ‰¾åˆ° train/val/test maskã€‚")


def main():
    """ä¸»å‡½æ•°ï¼Œéå†æ‰€æœ‰å®¢æˆ·ç«¯æ–‡ä»¶å¹¶è¿›è¡Œåˆ†æã€‚"""
    print(f"âœ¨ æ­£åœ¨åˆ†æå®¢æˆ·ç«¯æ•°æ®é›†ç›®å½•: {DATA_DIR}")

    if not os.path.isdir(DATA_DIR):
        print(f"âŒ é”™è¯¯: ç›®å½• {DATA_DIR} ä¸å­˜åœ¨ã€‚è¯·æ£€æŸ¥é…ç½®ã€‚")
        return

    if not PYG_DATA_FILES:
        print(f"âŒ é”™è¯¯: ç›®å½•ä¸­æœªæ‰¾åˆ°ä»»ä½• .pt æ–‡ä»¶ã€‚")
        return

    # å…¨å±€ç»Ÿè®¡ (å¯é€‰ï¼Œä½†å¾ˆæœ‰ç”¨)
    all_client_nodes = []

    for client_id, file_path in enumerate(PYG_DATA_FILES):
        analyze_client_data(file_path, client_id)

        try:
            data: Data = torch.load(file_path)
            all_client_nodes.append(data.num_nodes)
        except:
            pass

    # æ‰“å°å…¨å±€æ±‡æ€»ä¿¡æ¯
    if all_client_nodes:
        total_nodes = sum(all_client_nodes)
        min_nodes = min(all_client_nodes)
        max_nodes = max(all_client_nodes)
        avg_nodes = np.mean(all_client_nodes)

        print("\n==================== ğŸ“Š å…¨å±€æ±‡æ€» ====================")
        print(f"  - å®¢æˆ·ç«¯æ€»æ•°: {len(PYG_DATA_FILES)}")
        print(f"  - æ‰€æœ‰å®¢æˆ·ç«¯èŠ‚ç‚¹æ€»æ•°: {total_nodes}")
        print(f"  - å®¢æˆ·ç«¯èŠ‚ç‚¹æ•°èŒƒå›´: {min_nodes} (Min) ~ {max_nodes} (Max)")
        print(f"  - å®¢æˆ·ç«¯å¹³å‡èŠ‚ç‚¹æ•°: {avg_nodes:.2f}")
        print("======================================================")


if __name__ == "__main__":
    main()