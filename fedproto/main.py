import os
import torch
import torch.nn.functional as F
import numpy as np
import random
import copy
from client import Client
# å¯¼å…¥æ‚¨æ–°çš„æ¨¡å‹æ–‡ä»¶
from model.gcn import GCN
from model.graphsage import GraphSAGE
from model.resmlp import ResMLP
from torch_geometric.data import Data
from torch_geometric.utils import to_undirected


# --- 1. æ•°æ®åˆ’åˆ†é€»è¾‘ï¼ˆä¿æŒä¸å˜ï¼‰ ---
def split_client_data_for_node_classification(data: Data, val_ratio=0.2, test_ratio=0.2):
    """
    æ ¹æ®ç»™å®šçš„æ¯”ä¾‹ï¼Œä¸ºå®¢æˆ·ç«¯æ•°æ®ç”Ÿæˆ train/val/test èŠ‚ç‚¹ Masksã€‚
    """
    num_nodes = data.num_nodes
    num_labeled_nodes = num_nodes

    indices = torch.randperm(num_labeled_nodes)

    num_test = int(test_ratio * num_labeled_nodes)
    num_val = int(val_ratio * num_labeled_nodes)
    num_train = num_labeled_nodes - num_test - num_val

    if num_train <= 0:
        raise ValueError("è®­ç»ƒé›†å¤§å°ä¸ºé›¶æˆ–è´Ÿæ•°ï¼Œè¯·æ£€æŸ¥åˆ’åˆ†æ¯”ä¾‹ã€‚")

    test_indices = indices[:num_test]
    val_indices = indices[num_test:num_test + num_val]
    train_indices = indices[num_test + num_val:]

    train_mask = torch.zeros(num_nodes, dtype=torch.bool, device=data.x.device)
    val_mask = torch.zeros(num_nodes, dtype=torch.bool, device=data.x.device)
    test_mask = torch.zeros(num_nodes, dtype=torch.bool, device=data.x.device)

    train_mask[train_indices] = True
    val_mask[val_indices] = True
    test_mask[test_indices] = True

    data.train_mask = train_mask
    data.val_mask = val_mask
    data.test_mask = test_mask

    data.edge_index = to_undirected(data.edge_index, num_nodes=num_nodes)

    return data


# --- 2. å®¢æˆ·ç«¯åŠ è½½é€»è¾‘ï¼ˆé€‚é… FedProtoï¼‰ ---
def load_all_clients(pyg_data_paths, encoder_params, classifier_params, training_params, device, lambda_proto,
                     num_classes, prototype_dim):  # <--- ã€ä¿®æ”¹ç‚¹ã€‘æ–°å¢ prototype_dim
    clients = []

    print(f"æ£€æµ‹åˆ°ç±»åˆ«æ€»æ•° (Output Dim): {num_classes}")
    print(f"åŸå‹ç»´åº¦ (Prototype Dim): {prototype_dim}")

    for client_id, path in enumerate(pyg_data_paths):
        raw_data = torch.load(path)

        data = split_client_data_for_node_classification(
            raw_data,
            val_ratio=0.2,
            test_ratio=0.2
        )
        data = data.to(device)

        # ç¼–ç å™¨å®ä¾‹åŒ–
        encoder = GraphSAGE(
            input_dim=encoder_params['input_dim'],
            hidden_dim=encoder_params['hidden_dim'],
            output_dim=prototype_dim,
            num_layers=encoder_params['num_layers'],
            dropout=encoder_params['dropout']
        )

        # åˆ†ç±»å™¨å®ä¾‹åŒ–
        classifier = ResMLP(
            input_dim=prototype_dim,
            hidden_dim=classifier_params['hidden_dim'],
            output_dim=num_classes,
            num_layers=classifier_params['num_layers'],
            dropout=classifier_params['dropout']
        )

        # ã€ä¿®æ”¹ç‚¹ã€‘å®ä¾‹åŒ– Client æ—¶ä¼ å…¥ prototype_dim
        client = Client(
            client_id=client_id,
            data=data,
            encoder=encoder,
            classifier=classifier,
            device=device,
            lr=training_params['lr'],
            weight_decay=training_params['weight_decay'],
            lambda_proto=lambda_proto,
            num_classes=num_classes,
            prototype_dim=prototype_dim  # <--- ä¼ å…¥ç»´åº¦
        )
        clients.append(client)

    return clients, num_classes


# --- 3. FedAvg èšåˆé€»è¾‘ï¼ˆç”¨äºæ¨¡å‹æƒé‡ï¼‰ ---
def average_state_dicts(state_dicts):
    """æ ‡å‡† FedAvg æƒé‡å¹³å‡"""
    avg_state = {}
    for key in state_dicts[0].keys():
        avg_state[key] = torch.stack([sd[key].float() for sd in state_dicts], dim=0).mean(dim=0)
    return avg_state


# --- 4. FedProto æ ¸å¿ƒï¼šåŸå‹èšåˆé€»è¾‘ ---
def aggregate_prototypes(clients, num_classes, prototype_dim, device):
    """
    èšåˆæ‰€æœ‰å®¢æˆ·ç«¯ä¸Šä¼ çš„æœ¬åœ°åŸå‹ï¼Œè®¡ç®—åŠ æƒå¹³å‡çš„å…¨å±€åŸå‹ã€‚

    è¿”å›: global_prototypes (torch.Tensor of shape [num_classes, prototype_dim])
    """
    # åˆå§‹åŒ–å…¨å±€åŸå‹å’Œè®¡æ•°å™¨
    global_prototypes = torch.zeros(num_classes, prototype_dim).to(device)
    global_counts = torch.zeros(num_classes).to(device)

    # 1. æ”¶é›†æ‰€æœ‰å®¢æˆ·ç«¯çš„æœ¬åœ°åŸå‹å’Œè®¡æ•°
    # æ³¨æ„ï¼šget_local_prototypes åœ¨ client.py ä¸­å·²å®ç°ï¼Œæ˜¯åœ¨è¯„ä¼°æ¨¡å¼ä¸‹è¿›è¡Œçš„æ— æ¢¯åº¦è®¡ç®—
    all_local_protos_and_counts = []
    for client in clients:
        # get_local_prototypes è¿”å› (dict: {class_id: proto}, list: [(class_id, count)])
        local_protos, proto_counts = client.get_local_prototypes()
        all_local_protos_and_counts.append((local_protos, proto_counts))

    # 2. éå†æ‰€æœ‰å®¢æˆ·ç«¯ï¼Œæ‰§è¡ŒåŠ æƒèšåˆ
    for local_protos, proto_counts in all_local_protos_and_counts:
        for class_id, count in proto_counts:
            prototype = local_protos[class_id].to(device)

            # ç´¯åŠ ï¼šåŸå‹ * æ ·æœ¬æ•°
            global_prototypes[class_id] += prototype * count
            # ç´¯åŠ ï¼šæ ·æœ¬æ•°
            global_counts[class_id] += count

    # 3. è®¡ç®—åŠ æƒå¹³å‡
    for class_id in range(num_classes):
        count = global_counts[class_id]
        if count > 0:
            global_prototypes[class_id] /= count
        # å¦åˆ™ï¼Œè¯¥ç±»åˆ«æ²¡æœ‰æ ·æœ¬ï¼ŒåŸå‹ä¿æŒé›¶å‘é‡

    return global_prototypes


# --- 5. è¯„ä¼°é€»è¾‘ï¼ˆä¿æŒä¸å˜ï¼‰ ---
def evaluate_all_clients(clients, use_test=False):
    """è¯„ä¼°æ‰€æœ‰å®¢æˆ·ç«¯æ¨¡å‹å¹¶è®¡ç®—å¹³å‡æŒ‡æ ‡"""
    metrics = []
    for client in clients:
        acc, recall, precision, f1 = client.evaluate(use_test=use_test)
        metrics.append((acc, recall, precision, f1))
        print(f"Client {client.client_id}: Acc={acc:.4f}, Recall={recall:.4f}, "
              f"Prec={precision:.4f}, F1={f1:.4f}")

    if metrics:
        avg_metrics = torch.tensor(metrics).mean(dim=0).tolist()
        print(f"\n===> Average Metrics: Acc={avg_metrics[0]:.4f}, Recall={avg_metrics[1]:.4f}, "
              f"Prec={avg_metrics[2]:.4f}, F1={avg_metrics[3]:.4f}")
        return avg_metrics
    return [0.0, 0.0, 0.0, 0.0]


# --- 6. ä¸»è®­ç»ƒæµç¨‹ ---
if __name__ == "__main__":

    def set_seed(seed):
        random.seed(seed)
        np.random.seed(seed)
        torch.manual_seed(seed)
        if torch.cuda.is_available():
            torch.cuda.manual_seed(seed)
            torch.backends.cudnn.deterministic = True
            torch.backends.cudnn.benchmark = False


    RANDOM_SEED = 42
    set_seed(RANDOM_SEED)

    # 1. é…ç½®è·¯å¾„ä¸å‚æ•°
    data_dir = "../parsed_dataset/cs"
    pyg_data_files = sorted([os.path.join(data_dir, f) for f in os.listdir(data_dir) if f.endswith(".pt")])

    if not pyg_data_files:
        print(f"âŒ é”™è¯¯: æœªæ‰¾åˆ°ä»»ä½• PyG å­å›¾æ–‡ä»¶åœ¨ {data_dir}ã€‚è¯·æ£€æŸ¥è·¯å¾„å’Œæ–‡ä»¶åç¼€ã€‚")
        exit()

    # è¯»å–ç¬¬ä¸€ä¸ªæ–‡ä»¶æ¥ç¡®å®šè¾“å…¥ç»´åº¦å’Œç±»åˆ«æ•°
    initial_data = torch.load(pyg_data_files[0])
    initial_x = initial_data.x
    initial_y = initial_data.y

    input_dim = initial_x.shape[1] if initial_x is not None and initial_x.dim() > 0 else 1
    # ç¡®ä¿ç±»åˆ«æ•°è®¡ç®—åŸºäºæœ‰æ•ˆçš„æ ‡ç­¾
    num_classes_calc = initial_y.max().item() + 1 if initial_y is not None and initial_y.numel() > 0 and initial_y.max().item() >= 0 else 7

    # å…³é”®ä¿®æ”¹ A: FedProto å‚æ•°
    LAMBDA_PROTO = 1.0  # <--- è®¾ç½®åŸå‹æŸå¤±æ­£åˆ™åŒ–æƒé‡ã€‚

    encoder_params = {
        'input_dim': input_dim,
        'hidden_dim': 128,
        'output_dim': 64,  # åŸå‹ç»´åº¦ (D_emb)
        'num_layers': 3,
        'dropout': 0.5
    }

    classifier_params = {
        'hidden_dim': 128,
        'num_layers': 3,
        'dropout': 0.3
    }

    training_params = {
        'lr': 0.001,
        'weight_decay': 1e-4,
        'local_epochs': 5
    }

    num_rounds = 600
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

    # è·å–åŸå‹ç»´åº¦ (æ‰€æœ‰å®¢æˆ·ç«¯å…±äº«)
    prototype_dim = encoder_params['output_dim']

    # 2. åˆå§‹åŒ–å®¢æˆ·ç«¯
    # ã€ä¿®æ”¹ç‚¹ã€‘è°ƒç”¨ load_all_clients æ—¶ä¼ å…¥ prototype_dim
    clients, num_classes = load_all_clients(
        pyg_data_files,
        encoder_params,
        classifier_params,
        training_params,
        device,
        LAMBDA_PROTO,
        num_classes_calc,
        prototype_dim
    )

    # åˆå§‹å…¨å±€åŸå‹ï¼šå…¨é›¶å‘é‡
    global_prototypes = torch.zeros(num_classes, prototype_dim).to(device)

    # é¦–æ¬¡åŒæ­¥å…¨å±€åŸå‹ï¼ˆå…¨é›¶ï¼‰
    for client in clients:
        client.set_global_prototypes(global_prototypes)

    best_f1 = -1
    best_encoder_state = None
    best_classifier_state = None
    best_prototypes = None  # ä¿å­˜æœ€ä½³åŸå‹çŠ¶æ€

    print(f"\nğŸš€ Federated Algorithm: FedProto (Lambda={LAMBDA_PROTO})")
    print("================ Federated Training Start ================\n")

    for rnd in range(1, num_rounds + 1):
        print(f"\n--- Round {rnd} ---")

        # 3. æ¯ä¸ªå®¢æˆ·ç«¯æœ¬åœ°è®­ç»ƒ
        for client in clients:
            for _ in range(training_params['local_epochs']):
                loss = client.train()

        # 4. èšåˆï¼šæ¨¡å‹æƒé‡ (FedAvg) + åŸå‹ (FedProto)

        # 4a. æ¨¡å‹æƒé‡èšåˆ (FedAvg æ–¹å¼)
        encoder_states = [copy.deepcopy(client.get_encoder_state()) for client in clients]
        classifier_states = [copy.deepcopy(client.get_classifier_state()) for client in clients]
        global_encoder_state = average_state_dicts(encoder_states)
        global_classifier_state = average_state_dicts(classifier_states)

        # 4b. åŸå‹èšåˆ (FedProto æ–¹å¼)
        global_prototypes = aggregate_prototypes(clients, num_classes, prototype_dim, device)

        # 5. åŒæ­¥å‚æ•°
        for client in clients:
            # åŒæ­¥æ¨¡å‹æƒé‡
            client.set_encoder_state(global_encoder_state)
            client.set_classifier_state(global_classifier_state)
            # åŒæ­¥å…¨å±€åŸå‹
            client.set_global_prototypes(global_prototypes)

        # 6. è”é‚¦è¯„ä¼°
        avg_acc, avg_recall, avg_prec, avg_f1 = evaluate_all_clients(clients, use_test=False)

        if avg_f1 > best_f1:
            best_f1 = avg_f1
            best_encoder_state = global_encoder_state
            best_classifier_state = global_classifier_state
            best_prototypes = global_prototypes
            print("===> New best global model and prototypes saved.")

    print("\n================ Federated Training Finished ================\n")

    # 7. æœ€ç»ˆæ¨¡å‹è¯„ä¼°
    for client in clients:
        client.set_encoder_state(best_encoder_state)
        client.set_classifier_state(best_classifier_state)
        client.set_global_prototypes(best_prototypes)

    print("\n================ Final Evaluation on Test Set ================")
    evaluate_all_clients(clients, use_test=True)

    print("---------------------------------------------------------------")
    print(f"æœ€ç»ˆæœ€ä½³ F1 Score (Validation): {best_f1:.4f}")
    print("---------------------------------------------------------------")
